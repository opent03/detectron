{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from baselines.cifar10_loader import load_and_process_cifar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_item(x, is_cuda):\n",
    "    \"\"\"get the numpy value from a torch tensor.\"\"\"\n",
    "    if is_cuda:\n",
    "        x = x.cpu().detach().numpy()\n",
    "    else:\n",
    "        x = x.detach().numpy()\n",
    "    return x\n",
    "\n",
    "def MatConvert(x, device, dtype):\n",
    "    \"\"\"convert the numpy to a torch tensor.\"\"\"\n",
    "    x = torch.from_numpy(x).to(device, dtype)\n",
    "    return x\n",
    "\n",
    "def Pdist2(x, y):\n",
    "    \"\"\"compute the paired distance between x and y.\"\"\"\n",
    "    x_norm = (x ** 2).sum(1).view(-1, 1)\n",
    "    if y is not None:\n",
    "        y_norm = (y ** 2).sum(1).view(1, -1)\n",
    "    else:\n",
    "        y = x\n",
    "        y_norm = x_norm.view(1, -1)\n",
    "    Pdist = x_norm + y_norm - 2.0 * torch.mm(x, torch.transpose(y, 0, 1))\n",
    "    Pdist[Pdist<0]=0\n",
    "    return Pdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def h1_mean_var_gram(Kx, Ky, Kxy, is_var_computed, use_1sample_U=True):\n",
    "    \"\"\"compute value of MMD and std of MMD using kernel matrix.\"\"\"\n",
    "    Kxxy = torch.cat((Kx,Kxy),1)\n",
    "    Kyxy = torch.cat((Kxy.transpose(0,1),Ky),1)\n",
    "    Kxyxy = torch.cat((Kxxy,Kyxy),0)\n",
    "    nx = Kx.shape[0]\n",
    "    ny = Ky.shape[0]\n",
    "    is_unbiased = True\n",
    "    if is_unbiased:\n",
    "        xx = torch.div((torch.sum(Kx) - torch.sum(torch.diag(Kx))), (nx * (nx - 1)))\n",
    "        yy = torch.div((torch.sum(Ky) - torch.sum(torch.diag(Ky))), (ny * (ny - 1)))\n",
    "        # one-sample U-statistic.\n",
    "        if use_1sample_U:\n",
    "            xy = torch.div((torch.sum(Kxy) - torch.sum(torch.diag(Kxy))), (nx * (ny - 1)))\n",
    "        else:\n",
    "            xy = torch.div(torch.sum(Kxy), (nx * ny))\n",
    "        mmd2 = xx - 2 * xy + yy\n",
    "    else:\n",
    "        xx = torch.div((torch.sum(Kx)), (nx * nx))\n",
    "        yy = torch.div((torch.sum(Ky)), (ny * ny))\n",
    "        # one-sample U-statistic.\n",
    "        if use_1sample_U:\n",
    "            xy = torch.div((torch.sum(Kxy)), (nx * ny))\n",
    "        else:\n",
    "            xy = torch.div(torch.sum(Kxy), (nx * ny))\n",
    "        mmd2 = xx - 2 * xy + yy\n",
    "    if not is_var_computed:\n",
    "        return mmd2, None, Kxyxy\n",
    "    hh = Kx+Ky-Kxy-Kxy.transpose(0,1)\n",
    "    V1 = torch.dot(hh.sum(1)/ny,hh.sum(1)/ny) / ny\n",
    "    V2 = (hh).sum() / (nx) / nx\n",
    "    varEst = 4*(V1 - V2**2)\n",
    "    if  varEst == 0.0:\n",
    "        print('error_var!!'+str(V1))\n",
    "    return mmd2, varEst, Kxyxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MMDu(Fea, len_s, Fea_org, sigma, sigma0=0.1, epsilon = 10**(-10), is_smooth=True, is_var_computed=True, use_1sample_U=True):\n",
    "    \"\"\"compute value of deep-kernel MMD and std of deep-kernel MMD using merged data.\"\"\"\n",
    "    X = Fea[0:len_s, :] # fetch the sample 1 (features of deep networks)\n",
    "    Y = Fea[len_s:, :] # fetch the sample 2 (features of deep networks)\n",
    "    X_org = Fea_org[0:len_s, :] # fetch the original sample 1\n",
    "    Y_org = Fea_org[len_s:, :] # fetch the original sample 2\n",
    "    L = 1 # generalized Gaussian (if L>1)\n",
    "\n",
    "    nx = X.shape[0]\n",
    "    ny = Y.shape[0]\n",
    "    Dxx = Pdist2(X, X)\n",
    "    Dyy = Pdist2(Y, Y)\n",
    "    Dxy = Pdist2(X, Y)\n",
    "    Dxx_org = Pdist2(X_org, X_org)\n",
    "    Dyy_org = Pdist2(Y_org, Y_org)\n",
    "    Dxy_org = Pdist2(X_org, Y_org)\n",
    "    if is_smooth:\n",
    "        Kx = (1-epsilon) * torch.exp(-(Dxx / sigma0)**L -Dxx_org / sigma) + epsilon * torch.exp(-Dxx_org / sigma)\n",
    "        Ky = (1-epsilon) * torch.exp(-(Dyy / sigma0)**L -Dyy_org / sigma) + epsilon * torch.exp(-Dyy_org / sigma)\n",
    "        Kxy = (1-epsilon) * torch.exp(-(Dxy / sigma0)**L -Dxy_org / sigma) + epsilon * torch.exp(-Dxy_org / sigma)\n",
    "    else:\n",
    "        Kx = torch.exp(-Dxx / sigma0)\n",
    "        Ky = torch.exp(-Dyy / sigma0)\n",
    "        Kxy = torch.exp(-Dxy / sigma0)\n",
    "        \n",
    "    return h1_mean_var_gram(Kx, Ky, Kxy, is_var_computed, use_1sample_U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Latent space model '''\n",
    "\n",
    "class ModelLatentF(torch.nn.Module):\n",
    "    \"\"\"define deep networks.\"\"\"\n",
    "    def __init__(self, x_in, H, x_out):\n",
    "        \"\"\"Init latent features.\"\"\"\n",
    "        super(ModelLatentF, self).__init__()\n",
    "        self.restored = False\n",
    "\n",
    "        self.latent = torch.nn.Sequential(\n",
    "            torch.nn.Linear(x_in, H, bias=True),\n",
    "            torch.nn.Softplus(),\n",
    "            torch.nn.Linear(H, H, bias=True),\n",
    "            torch.nn.Softplus(),\n",
    "            torch.nn.Linear(H, H, bias=True),\n",
    "            torch.nn.Softplus(),\n",
    "            torch.nn.Linear(H, x_out, bias=True),\n",
    "        )\n",
    "    def forward(self, input):\n",
    "        \"\"\"Forward the LeNet.\"\"\"\n",
    "        fealant = self.latent(input)\n",
    "        return fealant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Custom dataset class '''\n",
    "\n",
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        self.n = len(X)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.Y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Deep Kernel MMD class'''\n",
    "\n",
    "class DK_MMD:\n",
    "    def __init__(self, n, X, Y, n_features=10, hidden_dim=20, out_features=20, lr=5e-5, train_epochs=1000, alpha=0.05, batch_size=32, P=None, Q=None):\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.lr = lr\n",
    "        self.n = n # number of samples in one set\n",
    "        self.batch_size=batch_size\n",
    "        self.alpha = alpha\n",
    "        self.train_epochs = train_epochs\n",
    "        self.losses = torch.zeros(size=(self.train_epochs,)) # collecting loss data\n",
    "        self.P, self.Q = P, Q # DEFAULTS TO NONE\n",
    "        self.oracle = True if self.P is not None else False\n",
    "        self.dtype = torch.float\n",
    "        \n",
    "        if self.oracle:\n",
    "            print('Distribution oracles provided. Will be using oracles instead of samples.')\n",
    "            \n",
    "        # feature map\n",
    "        self.feature_map = ModelLatentF(n_features, hidden_dim, out_features) \n",
    "        self.feature_map = self.feature_map.to(self.device)\n",
    "        \n",
    "        # Training stuff\n",
    "        self.eps_opt = torch.log(MatConvert(np.random.rand(1) * 10 ** (-10), self.device, torch.float))\n",
    "        self.eps_opt.requires_grad = True\n",
    "        self.sigma_q = MatConvert(np.ones(1) * np.sqrt(2*n_features), self.device, torch.float)\n",
    "        self.sigma_q.requires_grad = True\n",
    "        self.sigma_phi = MatConvert(np.ones(1) * np.sqrt(0.005), self.device, torch.float)\n",
    "        self.sigma_phi.requires_grad = True\n",
    "        \n",
    "        print('n:{}\\t d: {}'.format(self.n, n_features))\n",
    "        print('Epsilon: {:.6f}'.format(self.eps_opt.item()))\n",
    "        \n",
    "        self.optimizer = optim.Adam(list(self.feature_map.parameters()) + [self.eps_opt] + [self.sigma_phi] + [self.sigma_q], lr=self.lr)\n",
    "        # initialize data variables.\n",
    "        idx = np.random.choice(len(X), self.n, replace=False)\n",
    "        idy = np.random.choice(len(Y), self.n, replace=False)\n",
    "        \n",
    "        self.dataset = CustomDataset(X[idx], Y[idy])\n",
    "        self.loader = DataLoader(self.dataset, batch_size=self.batch_size, shuffle=True, num_workers=3, pin_memory=True)\n",
    "    \n",
    "    def save(self, save_dir, name):\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        torch.save(self.feature_map.state_dict(), os.path.join(save_dir, name))\n",
    "    \n",
    "    def load(self, pth):\n",
    "        try: \n",
    "            self.feature_map.load_state_dict(torch.load(pth))\n",
    "            self.feature_map = self.feature_map.to(self.device)\n",
    "        except:\n",
    "            print('Unable to load model, path not found.')\n",
    "            exit(1)\n",
    "    \n",
    "    def train(self):\n",
    "        ''' Trains the deep kernel MMD'''\n",
    "        for e in tqdm(range(self.train_epochs)):            \n",
    "            # Printables\n",
    "            mmd_value_temp = None\n",
    "            mmd_std_temp = None\n",
    "            STAT_u = None\n",
    "            \n",
    "            # if using distribution oracles to train, regen every epoch\n",
    "            if self.oracle:\n",
    "                X, Y = self.P.sample(self.n), self.Q.sample(self.n)\n",
    "                self.dataset = CustomDataset(X, Y)\n",
    "                self.loader = DataLoader(self.dataset, batch_size=self.batch_size, shuffle=True, num_workers=3, pin_memory=True)\n",
    "                \n",
    "            for idx, (batch_X, batch_Y) in enumerate(self.loader):\n",
    "                eps = torch.exp(self.eps_opt) / (1 + torch.exp(self.eps_opt))\n",
    "                sigma_phi = self.sigma_phi ** 2\n",
    "                sigma_q = self.sigma_q ** 2\n",
    "                S = np.concatenate((batch_X, batch_Y), axis=0)\n",
    "                S = MatConvert(S, self.device, self.dtype)\n",
    "                model_output = self.feature_map(S)\n",
    "                mmd, var, _ = MMDu(model_output, int(len(S)/2), S, sigma=sigma_q, sigma0=sigma_phi, epsilon=eps)\n",
    "                mmd_value_temp = -1 * (mmd + 1e-8)\n",
    "                mmd_std_temp = torch.sqrt(var + 1e-8)\n",
    "                if mmd_std_temp.item() == 0:\n",
    "                    print('error 1!!')\n",
    "                if np.isnan(mmd_std_temp.item()):\n",
    "                    print('error 2!!')\n",
    "                STAT_u = torch.div(mmd_value_temp, mmd_std_temp)\n",
    "                self.optimizer.zero_grad()\n",
    "                STAT_u.backward(retain_graph=True)\n",
    "                self.optimizer.step()\n",
    "            if e % 100 ==0:\n",
    "                print(\"mmd: \", -1 * mmd_value_temp.item(), \"mmd_std: \", mmd_std_temp.item(), \"Statistic: \",\n",
    "                    -1 * STAT_u.item())  # ,\"Reg: \", loss1.item()\n",
    "                \n",
    "            \n",
    "        print('Done training!')\n",
    "        return None\n",
    "    \n",
    "    def get_distance(self, X, Y):\n",
    "        eps = torch.exp(self.eps_opt) / (1 + torch.exp(self.eps_opt))\n",
    "        if len(X) > len(Y):\n",
    "            idx = np.random.choice(len(X), len(Y), replace=False)\n",
    "            X = X[idx]\n",
    "        S = np.concatenate((X, Y), axis=0)\n",
    "        S = MatConvert(S, self.device, self.dtype)\n",
    "        model_output = self.feature_map(S)\n",
    "        mmd, _, _ = MMDu(model_output, len(X), S, sigma=self.sigma_q ** 2, sigma0=self.sigma_phi ** 2, epsilon=eps)\n",
    "        mmd = get_item(mmd, True if torch.cuda.is_available() else False)\n",
    "        return mmd\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load CIFAR10.1 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA explained variance ratio:  0.8065923235518608\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = load_and_process_cifar(n_components=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmd_config = {\n",
    "    'n': len(x_test),  # lower of the two\n",
    "    'X': x_train,\n",
    "    'Y': x_test,\n",
    "    'n_features': 20,\n",
    "    'hidden_dim': 32,\n",
    "    'lr': 1e-4,\n",
    "    'train_epochs': 500,\n",
    "    'P': None,\n",
    "    'Q': None\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n:2000\t d: 20\n",
      "Epsilon: -23.411371\n"
     ]
    }
   ],
   "source": [
    "mmd = DK_MMD(**mmd_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error_var!!tensor(0.0039, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/500 [00:00<07:53,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mmd:  2.7001860871678218e-05 mmd_std:  0.00015780102694407105 Statistic:  0.17111334204673767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/500 [00:01<07:25,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error_var!!tensor(0.0039, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 3/500 [00:02<07:16,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error_var!!tensor(0.0039, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 4/500 [00:03<07:13,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error_var!!tensor(0.0039, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 5/500 [00:04<07:12,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error_var!!tensor(0.0039, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 11/500 [00:09<07:00,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error_var!!tensor(0.0156, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 101/500 [01:28<06:23,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mmd:  0.0011387683916836977 mmd_std:  0.009525138884782791 Statistic:  0.11955399066209793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 201/500 [02:57<04:14,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mmd:  -0.0004990394227206707 mmd_std:  0.004922206047922373 Statistic:  -0.10138531774282455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 301/500 [04:26<02:54,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mmd:  0.0040547591634094715 mmd_std:  0.01397007703781128 Statistic:  0.29024600982666016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 401/500 [05:50<01:20,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mmd:  0.0022892665583640337 mmd_std:  0.005754383746534586 Statistic:  0.3978300094604492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [07:10<00:00,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done training!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "mmd.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmd.save('.', 'mmd_cifar_weights.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmd.load('baselines/mmd_cifar_weights.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:01<00:00, 301.92it/s]\n"
     ]
    }
   ],
   "source": [
    "from baselines.divergence import permutation_test\n",
    "flag, distr, est = permutation_test(mmd, x_train, x_test, 500, 0.05, enable_tqdm=True, max_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.lines.Line2D at 0x7f1c9171f460>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(distr)\n",
    "plt.axvline(est, c='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
