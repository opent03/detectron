{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from cifar10_loader import load_and_process_cifar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_item(x, is_cuda):\n",
    "    \"\"\"get the numpy value from a torch tensor.\"\"\"\n",
    "    if is_cuda:\n",
    "        x = x.cpu().detach().numpy()\n",
    "    else:\n",
    "        x = x.detach().numpy()\n",
    "    return x\n",
    "\n",
    "def MatConvert(x, device, dtype):\n",
    "    \"\"\"convert the numpy to a torch tensor.\"\"\"\n",
    "    x = torch.from_numpy(x).to(device, dtype)\n",
    "    return x\n",
    "\n",
    "def Pdist2(x, y):\n",
    "    \"\"\"compute the paired distance between x and y.\"\"\"\n",
    "    x_norm = (x ** 2).sum(1).view(-1, 1)\n",
    "    if y is not None:\n",
    "        y_norm = (y ** 2).sum(1).view(1, -1)\n",
    "    else:\n",
    "        y = x\n",
    "        y_norm = x_norm.view(1, -1)\n",
    "    Pdist = x_norm + y_norm - 2.0 * torch.mm(x, torch.transpose(y, 0, 1))\n",
    "    Pdist[Pdist<0]=0\n",
    "    return Pdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "def h1_mean_var_gram(Kx, Ky, Kxy, is_var_computed, use_1sample_U=True):\n",
    "    \"\"\"compute value of MMD and std of MMD using kernel matrix.\"\"\"\n",
    "    Kxxy = torch.cat((Kx,Kxy),1)\n",
    "    Kyxy = torch.cat((Kxy.transpose(0,1),Ky),1)\n",
    "    Kxyxy = torch.cat((Kxxy,Kyxy),0)\n",
    "    nx = Kx.shape[0]\n",
    "    ny = Ky.shape[0]\n",
    "    is_unbiased = True\n",
    "    if is_unbiased:\n",
    "        xx = torch.div((torch.sum(Kx) - torch.sum(torch.diag(Kx))), (nx * (nx - 1)))\n",
    "        yy = torch.div((torch.sum(Ky) - torch.sum(torch.diag(Ky))), (ny * (ny - 1)))\n",
    "        # one-sample U-statistic.\n",
    "        if use_1sample_U:\n",
    "            xy = torch.div((torch.sum(Kxy) - torch.sum(torch.diag(Kxy))), (nx * (ny - 1)))\n",
    "        else:\n",
    "            xy = torch.div(torch.sum(Kxy), (nx * ny))\n",
    "        mmd2 = xx - 2 * xy + yy\n",
    "    else:\n",
    "        xx = torch.div((torch.sum(Kx)), (nx * nx))\n",
    "        yy = torch.div((torch.sum(Ky)), (ny * ny))\n",
    "        # one-sample U-statistic.\n",
    "        if use_1sample_U:\n",
    "            xy = torch.div((torch.sum(Kxy)), (nx * ny))\n",
    "        else:\n",
    "            xy = torch.div(torch.sum(Kxy), (nx * ny))\n",
    "        mmd2 = xx - 2 * xy + yy\n",
    "    if not is_var_computed:\n",
    "        return mmd2, None, Kxyxy\n",
    "    hh = Kx+Ky-Kxy-Kxy.transpose(0,1)\n",
    "    \n",
    "    V1 = torch.dot(hh.sum(1)/ny,hh.sum(1)/ny) / ny\n",
    "    V2 = (hh).sum() / (nx) / nx\n",
    "    varEst = torch.abs(4*(V1 - V2**2))\n",
    "    if np.isnan(varEst.item()):\n",
    "        print('yeet')\n",
    "        return None\n",
    "    #if  varEst == 0.0:\n",
    "    #    print('error_var!!'+str(V1))\n",
    "    return mmd2, varEst, (Kx, Ky, Kxy)#(Kxxy, Kyxy, Kxyxy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MMDu(Fea, len_s, Fea_org, sigma, sigma0=0.1, epsilon = 10**(-10), is_smooth=True, is_var_computed=True, use_1sample_U=True):\n",
    "    \"\"\"compute value of deep-kernel MMD and std of deep-kernel MMD using merged data.\"\"\"\n",
    "    X = Fea[0:len_s, :] # fetch the sample 1 (features of deep networks)\n",
    "    Y = Fea[len_s:, :] # fetch the sample 2 (features of deep networks)\n",
    "    X_org = Fea_org[0:len_s, :] # fetch the original sample 1\n",
    "    Y_org = Fea_org[len_s:, :] # fetch the original sample 2\n",
    "    L = 1 # generalized Gaussian (if L>1)\n",
    "\n",
    "    nx = X.shape[0]\n",
    "    ny = Y.shape[0]\n",
    "    Dxx = Pdist2(X, X)\n",
    "    Dyy = Pdist2(Y, Y)\n",
    "    Dxy = Pdist2(X, Y)\n",
    "    Dxx_org = Pdist2(X_org, X_org)\n",
    "    Dyy_org = Pdist2(Y_org, Y_org)\n",
    "    Dxy_org = Pdist2(X_org, Y_org)\n",
    "    if is_smooth:\n",
    "        Kx = (1-epsilon) * torch.exp(-(Dxx / sigma0)**L -Dxx_org / sigma) + epsilon * torch.exp(-Dxx_org / sigma)\n",
    "        Ky = (1-epsilon) * torch.exp(-(Dyy / sigma0)**L -Dyy_org / sigma) + epsilon * torch.exp(-Dyy_org / sigma)\n",
    "        Kxy = (1-epsilon) * torch.exp(-(Dxy / sigma0)**L -Dxy_org / sigma) + epsilon * torch.exp(-Dxy_org / sigma)\n",
    "    else:\n",
    "        Kx = torch.exp(-Dxx / sigma0)\n",
    "        Ky = torch.exp(-Dyy / sigma0)\n",
    "        Kxy = torch.exp(-Dxy / sigma0)\n",
    "    return h1_mean_var_gram(Kx, Ky, Kxy, is_var_computed, use_1sample_U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Latent space model '''\n",
    "\n",
    "class ModelLatentF(torch.nn.Module):\n",
    "    \"\"\"define deep networks.\"\"\"\n",
    "    def __init__(self, x_in, H, x_out):\n",
    "        \"\"\"Init latent features.\"\"\"\n",
    "        super(ModelLatentF, self).__init__()\n",
    "        self.restored = False\n",
    "\n",
    "        self.latent = torch.nn.Sequential(\n",
    "            torch.nn.Linear(x_in, H, bias=True),\n",
    "            torch.nn.Softplus(),\n",
    "            torch.nn.Linear(H, H, bias=True),\n",
    "            torch.nn.Softplus(),\n",
    "            torch.nn.Linear(H, H, bias=True),\n",
    "            torch.nn.Softplus(),\n",
    "            torch.nn.Linear(H, x_out, bias=True),\n",
    "        )\n",
    "    def forward(self, input):\n",
    "        \"\"\"Forward the LeNet.\"\"\"\n",
    "        fealant = self.latent(input)\n",
    "        return fealant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Custom dataset class '''\n",
    "\n",
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        self.n = len(X)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.Y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Deep Kernel MMD class'''\n",
    "\n",
    "class DK_MMD:\n",
    "    def __init__(self, n, X, Y, n_features=10, hidden_dim=20, out_features=20, lr=5e-5, train_epochs=1000, alpha=0.05, batch_size=32, P=None, Q=None):\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.lr = lr\n",
    "        self.n = n # number of samples in one set\n",
    "        self.batch_size=batch_size\n",
    "        self.alpha = alpha\n",
    "        self.train_epochs = train_epochs\n",
    "        self.losses = torch.zeros(size=(self.train_epochs,)) # collecting loss data\n",
    "        self.P, self.Q = P, Q # DEFAULTS TO NONE\n",
    "        self.oracle = True if self.P is not None else False\n",
    "        self.dtype = torch.float\n",
    "        \n",
    "        if self.oracle:\n",
    "            print('Distribution oracles provided. Will be using oracles instead of samples.')\n",
    "            \n",
    "        # feature map\n",
    "        self.feature_map = ModelLatentF(n_features, hidden_dim, out_features) \n",
    "        self.feature_map = self.feature_map.to(self.device)\n",
    "        \n",
    "        # Training stuff\n",
    "        self.eps_opt = torch.log(MatConvert(np.random.rand(1) * 10 ** (-10), self.device, torch.float))\n",
    "        self.eps_opt.requires_grad = True\n",
    "        self.sigma_q = MatConvert(np.ones(1) * np.sqrt(2*n_features), self.device, torch.float)\n",
    "        self.sigma_q.requires_grad = True\n",
    "        self.sigma_phi = MatConvert(np.ones(1) * np.sqrt(0.005), self.device, torch.float)\n",
    "        self.sigma_phi.requires_grad = True\n",
    "        \n",
    "        print('n:{}\\t d: {}'.format(self.n, n_features))\n",
    "        print('Epsilon: {:.6f}'.format(self.eps_opt.item()))\n",
    "        \n",
    "        self.optimizer = optim.Adam(list(self.feature_map.parameters()) + [self.eps_opt] + [self.sigma_phi] + [self.sigma_q], lr=self.lr)\n",
    "        # initialize data variables.\n",
    "        idx = np.random.choice(len(X), self.n, replace=False)\n",
    "        idy = np.random.choice(len(Y), self.n, replace=False)\n",
    "        \n",
    "        self.dataset = CustomDataset(X[idx], Y[idy])\n",
    "        self.loader = DataLoader(self.dataset, batch_size=self.batch_size, shuffle=True, num_workers=3, pin_memory=True)\n",
    "    \n",
    "    def save(self, save_dir, name):\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        torch.save(self.feature_map.state_dict(), os.path.join(save_dir, name))\n",
    "    \n",
    "    def load(self, pth):\n",
    "        try: \n",
    "            self.feature_map.load_state_dict(torch.load(pth))\n",
    "            self.feature_map = self.feature_map.to(self.device)\n",
    "        except:\n",
    "            print('Unable to load model, path not found.')\n",
    "            exit(1)\n",
    "    \n",
    "    def train(self):\n",
    "        ''' Trains the deep kernel MMD'''\n",
    "        for e in tqdm(range(self.train_epochs)):            \n",
    "            # Printables\n",
    "            mmd_value_temp = None\n",
    "            mmd_std_temp = None\n",
    "            STAT_u = None\n",
    "            \n",
    "            # if using distribution oracles to train, regen every epoch\n",
    "            if self.oracle:\n",
    "                X, Y = self.P.sample(self.n), self.Q.sample(self.n)\n",
    "                self.dataset = CustomDataset(X, Y)\n",
    "                self.loader = DataLoader(self.dataset, batch_size=self.batch_size, shuffle=True, num_workers=3, pin_memory=True)\n",
    "                \n",
    "            for idx, (batch_X, batch_Y) in enumerate(self.loader):\n",
    "                eps = torch.exp(self.eps_opt) / (1 + torch.exp(self.eps_opt))\n",
    "                sigma_phi = self.sigma_phi ** 2\n",
    "                sigma_q = self.sigma_q ** 2\n",
    "                \n",
    "                S = np.concatenate((batch_X, batch_Y), axis=0)\n",
    "                S = MatConvert(S, self.device, self.dtype)\n",
    "                \n",
    "                model_output = self.feature_map(S)\n",
    "                mmd, var, (Kx, Ky, Kxy) = MMDu(model_output, int(len(S)/2), S, sigma=sigma_q, sigma0=sigma_phi, epsilon=eps)\n",
    "                mmd_value_temp = -1 * (mmd + 1e-8)\n",
    "                mmd_std_temp = torch.sqrt(var + 1e-8) \n",
    "                if mmd_std_temp.item() == 0:\n",
    "                    print('error 1!!')\n",
    "                if np.isnan(mmd_std_temp.item()):\n",
    "                    print('error 2!!')\n",
    "                    nx = Kx.shape[0]\n",
    "                    ny = Ky.shape[0]\n",
    "                    hh = Kx+Ky-Kxy-Kxy.transpose(0,1)\n",
    "                    print()\n",
    "                    print(hh)\n",
    "                    print()\n",
    "                    V1 = torch.dot(hh.sum(1)/ny,hh.sum(1)/ny) / ny\n",
    "                    print(V1)\n",
    "                    print()\n",
    "                    V2 = (hh).sum() / (nx) / nx\n",
    "                    print(V2)\n",
    "                    varEst = 4*(V1 - V2**2) + 1e-8\n",
    "                    print('varEst', varEst)\n",
    "                    print('var:', var)\n",
    "                    stdtemp = torch.sqrt(varEst + 1e-8)\n",
    "                    print(stdtemp)\n",
    "                    print(mmd_value_temp)\n",
    "                    st = torch.div(mmd_value_temp, mmd_std_temp)\n",
    "                    print(st)\n",
    "                STAT_u = torch.div(mmd_value_temp, mmd_std_temp)\n",
    "                self.optimizer.zero_grad()\n",
    "                STAT_u.backward(retain_graph=True)\n",
    "                self.optimizer.step()\n",
    "            if e % 100 ==0:\n",
    "                print(\"mmd: \", -1 * mmd_value_temp.item(), \"mmd_std: \", mmd_std_temp.item(), \"Statistic: \",\n",
    "                    -1 * STAT_u.item())  # ,\"Reg: \", loss1.item()\n",
    "                \n",
    "            \n",
    "        print('Done training!')\n",
    "        return None\n",
    "    \n",
    "    def get_distance(self, X, Y):\n",
    "        eps = torch.exp(self.eps_opt) / (1 + torch.exp(self.eps_opt))\n",
    "        if len(X) > len(Y):\n",
    "            idx = np.random.choice(len(X), len(Y), replace=False)\n",
    "            X = X[idx]\n",
    "        S = np.concatenate((X, Y), axis=0)\n",
    "        S = MatConvert(S, self.device, self.dtype)\n",
    "        model_output = self.feature_map(S)\n",
    "        mmd, _, _ = MMDu(model_output, len(X), S, sigma=self.sigma_q ** 2, sigma0=self.sigma_phi ** 2, epsilon=eps)\n",
    "        mmd = get_item(mmd, True if torch.cuda.is_available() else False)\n",
    "        return mmd\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load CIFAR10.1 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA explained variance ratio:  0.8065884494863885\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "def load_cifar10_512():\n",
    "    with open('data/cifar10_x_train.npy', 'rb') as f:\n",
    "        x_train = np.load(f)\n",
    "    #with open('baselines/data/cifar10_x_test.npy', 'rb') as f:\n",
    "    #    x_test = np.load(f)\n",
    "    with open('data/cifar10_y_train.npy', 'rb') as f:\n",
    "        y_train = np.load(f)\n",
    "    #with open('baselines/data/cifar10_y_test.npy', 'rb') as f:\n",
    "    #    y_test = np.load(f)\n",
    "    return x_train, y_train\n",
    "\n",
    "def load_cifar101_512():\n",
    "    with open('data/cifar101_x_test.npy', 'rb') as f:\n",
    "        x_test = np.load(f)\n",
    "    with open('data/cifar10.1_v6_labels.npy', 'rb') as f:\n",
    "        y_test = np.load(f)\n",
    "    return x_test, y_test\n",
    "\n",
    "def load_and_process_cifar(n_components=10):\n",
    "    # load datasets -------------------------------\n",
    "    x_train, y_train = load_cifar10_512()\n",
    "    x_test, y_test = load_cifar101_512()\n",
    "    \n",
    "    xy_train = np.concatenate([x_train, np.expand_dims(y_train, axis=1)], axis=1)\n",
    "    np.random.shuffle(xy_train)\n",
    "    x_train, y_train = xy_train[:, :512], xy_train[:,512:]\n",
    "    \n",
    "    xy_test = np.concatenate([x_test, np.expand_dims(y_test, axis=1)], axis=1)\n",
    "    np.random.shuffle(xy_test)\n",
    "    x_test, y_test = xy_test[:, :512], xy_test[:,512:]\n",
    "    # PCA -----------------------------------------\n",
    "    pca = PCA(n_components=n_components)\n",
    "    pca.fit(x_train)\n",
    "    x_train_pca, x_test_pca = pca.transform(x_train), pca.transform(x_test)\n",
    "    print('PCA explained variance ratio: ', sum(pca.explained_variance_ratio_))\n",
    "    return x_train_pca, x_test_pca, y_train, y_test\n",
    "    \n",
    "    \n",
    "x_train, x_test, y_train, y_test = load_and_process_cifar(n_components=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(x_test)\n",
    "x_val, x_test = x_test[:1000], x_test[1000:]\n",
    "x_train = x_train[np.random.choice(len(x_train), 1000, replace=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmd_config = {\n",
    "    'n': 1000,  # lower of the two\n",
    "    'X': x_train,\n",
    "    'Y': x_test,\n",
    "    'n_features': 20,\n",
    "    'hidden_dim': 32,\n",
    "    'batch_size': 32,\n",
    "    'lr': 5e-5,\n",
    "    'train_epochs': 500,\n",
    "    'P': None,\n",
    "    'Q': None\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n:1000\t d: 20\n",
      "Epsilon: -25.962107\n"
     ]
    }
   ],
   "source": [
    "mmd = DK_MMD(**mmd_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/500 [00:00<01:06,  7.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mmd:  9.999994610154772e-09 mmd_std:  0.00015780102694407105 Statistic:  6.3370905991178e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 101/500 [00:13<00:53,  7.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mmd:  -2.738575312832836e-05 mmd_std:  0.0004345272609498352 Statistic:  -0.06302424520254135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 201/500 [00:26<00:39,  7.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mmd:  -0.0018509689252823591 mmd_std:  0.003556147450581193 Statistic:  -0.5204983353614807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 301/500 [00:39<00:25,  7.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mmd:  -0.0012094881385564804 mmd_std:  0.005689931567758322 Statistic:  -0.21256637573242188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 401/500 [00:52<00:13,  7.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mmd:  4.4057971535949036e-05 mmd_std:  0.000263826921582222 Statistic:  0.16699573397636414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [01:06<00:00,  7.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done training!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "mmd.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmd.save('.', 'mmd_cifar_weights.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmd.load('baselines/mmd_cifar_weights.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:00<00:00, 972.51it/s]\n"
     ]
    }
   ],
   "source": [
    "from divergence import permutation_test\n",
    "flag, distr, est = permutation_test(mmd, x_train, x_val, 500, 0.05, enable_tqdm=True, max_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.lines.Line2D at 0x7ff8fb609730>"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAigAAAGeCAYAAAC+dvpwAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/H5lhTAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAjo0lEQVR4nO3dfXBU5eG38W9CyCYEdkNAdpM2kVgpIFJA0LhKfWPHAClCpVVsiogM0QpajKOSKWD9VQ1QqhSMoI4FnQGpzAgqahwaBHwJAQK+ASKOKKm4oYrZJVFCIPfzh8N5XIlAdOPeSa7PzBmy59x7cp89YXLNyb7EGWOMAAAALBIf6wkAAAB8F4ECAACsQ6AAAADrECgAAMA6BAoAALAOgQIAAKxDoAAAAOsQKAAAwDoECgAAsE5CrCfwQzQ2Nmr//v3q0qWL4uLiYj0dAABwGowxOnTokDIyMhQff4prJKaZNmzYYH7zm9+Y9PR0I8msWrXqe8fedNNNRpJ56KGHItZ/8cUX5g9/+IPp0qWL8Xg85sYbbzSHDh067TlUVVUZSSwsLCwsLCytcKmqqjrl7/pmX0Gpq6vTgAEDdOONN+rqq6/+3nGrVq3Spk2blJGRccK2/Px8ffbZZ1q7dq0aGho0ceJEFRQUaPny5ac1hy5dukiSqqqq5Ha7m3sIAAAgGurqpOO/5/fvl1JSTjo8HA4rMzPT+T1+Ms0OlBEjRmjEiBEnHfPpp5/q1ltv1SuvvKK8vLyIbbt27VJpaam2bNmiIUOGSJIWLlyokSNHat68eU0GzXcd/7OO2+0mUAAAiJUOHf7/1273KQPluNN5ekbUnyTb2Nio8ePH684771S/fv1O2F5eXq7U1FQnTiQpEAgoPj5eFRUVTe6zvr5e4XA4YgEAAG1X1ANlzpw5SkhI0G233dbk9mAwqB49ekSsS0hIUFpamoLBYJP3KS4ulsfjcZbMzMxoTxsAAFgkqoFSWVmpf/7zn1q6dGlUX11TVFSkUCjkLFVVVVHbNwAAsE9UA+W1117TgQMHlJWVpYSEBCUkJOiTTz7RHXfcoZ49e0qSfD6fDhw4EHG/o0eP6uDBg/L5fE3u1+VyOc834XknAAC0fVF9H5Tx48crEAhErMvNzdX48eM1ceJESZLf71dNTY0qKys1ePBgSdK6devU2NionJycaE4HAAC0Us0OlNraWn344YfO7b179+qtt95SWlqasrKy1K1bt4jxHTt2lM/nU+/evSVJffv21fDhwzV58mQtXrxYDQ0Nmjp1qsaNG3dar+ABAABtX7P/xLN161YNGjRIgwYNkiQVFhZq0KBBmjVr1mnvY9myZerTp4+GDRumkSNHaujQoXrssceaOxUAANBGxRljTKwn0VzhcFgej0ehUIjnowAAECt1dVLnzt98XVt7Wm/Udrq/v/mwQAAAYB0CBQAAWIdAAQAA1iFQAACAdQgUAABgHQIFAABYJ6rvJAu0dT2nvxjrKTTbx7PzYj0FAGg2rqAAAADrECgAAMA6BAoAALAOgQIAAKxDoAAAAOsQKAAAwDoECgAAsA6BAgAArEOgAAAA6xAoAADAOgQKAACwDoECAACsQ6AAAADrECgAAMA6BAoAALAOgQIAAKxDoAAAAOsQKAAAwDoECgAAsA6BAgAArEOgAAAA6xAoAADAOgQKAACwDoECAACsQ6AAAADrECgAAMA6BAoAALAOgQIAAKxDoAAAAOsQKAAAwDoECgAAsE5CrCcAoGX1nP5irKfQbB/Pzov1FADEGFdQAACAdQgUAABgnWYHysaNGzVq1ChlZGQoLi5Oq1evdrY1NDTo7rvvVv/+/ZWSkqKMjAxdf/312r9/f8Q+Dh48qPz8fLndbqWmpmrSpEmqra390QcDAADahmYHSl1dnQYMGKCSkpITtn311Vfatm2bZs6cqW3btunZZ5/V7t27ddVVV0WMy8/P144dO7R27VqtWbNGGzduVEFBwQ8/CgAA0KY0+0myI0aM0IgRI5rc5vF4tHbt2oh1Dz/8sC644ALt27dPWVlZ2rVrl0pLS7VlyxYNGTJEkrRw4UKNHDlS8+bNU0ZGxg84DAAA0Ja0+HNQQqGQ4uLilJqaKkkqLy9XamqqEyeSFAgEFB8fr4qKiib3UV9fr3A4HLEAAIC2q0UD5fDhw7r77rt13XXXye12S5KCwaB69OgRMS4hIUFpaWkKBoNN7qe4uFgej8dZMjMzW3LaAAAgxlosUBoaGnTNNdfIGKNFixb9qH0VFRUpFAo5S1VVVZRmCQAAbNQib9R2PE4++eQTrVu3zrl6Ikk+n08HDhyIGH/06FEdPHhQPp+vyf25XC65XK6WmCoAALBQ1K+gHI+TPXv26D//+Y+6desWsd3v96umpkaVlZXOunXr1qmxsVE5OTnRng4AAGiFmn0Fpba2Vh9++KFze+/evXrrrbeUlpam9PR0/e53v9O2bdu0Zs0aHTt2zHleSVpamhITE9W3b18NHz5ckydP1uLFi9XQ0KCpU6dq3LhxvIIHAABI+gGBsnXrVl1++eXO7cLCQknShAkT9Ne//lXPP/+8JGngwIER93v11Vd12WWXSZKWLVumqVOnatiwYYqPj9fYsWO1YMGCH3gIAACgrWl2oFx22WUyxnzv9pNtOy4tLU3Lly9v7rcGAADtBJ/FAwAArEOgAAAA6xAoAADAOgQKAACwDoECAACsQ6AAAADrECgAAMA6BAoAALAOgQIAAKxDoAAAAOsQKAAAwDoECgAAsA6BAgAArEOgAAAA6xAoAADAOgQKAACwDoECAACsQ6AAAADrECgAAMA6BAoAALAOgQIAAKxDoAAAAOsQKAAAwDoECgAAsA6BAgAArEOgAAAA6xAoAADAOgQKAACwDoECAACsQ6AAAADrECgAAMA6BAoAALAOgQIAAKxDoAAAAOsQKAAAwDoECgAAsA6BAgAArEOgAAAA6xAoAADAOgQKAACwDoECAACs0+xA2bhxo0aNGqWMjAzFxcVp9erVEduNMZo1a5bS09OVnJysQCCgPXv2RIw5ePCg8vPz5Xa7lZqaqkmTJqm2tvZHHQgAAGg7mh0odXV1GjBggEpKSprcPnfuXC1YsECLFy9WRUWFUlJSlJubq8OHDztj8vPztWPHDq1du1Zr1qzRxo0bVVBQ8MOPAgAAtCkJzb3DiBEjNGLEiCa3GWM0f/58zZgxQ6NHj5YkPfXUU/J6vVq9erXGjRunXbt2qbS0VFu2bNGQIUMkSQsXLtTIkSM1b948ZWRk/IjDAQAAbUFUn4Oyd+9eBYNBBQIBZ53H41FOTo7Ky8slSeXl5UpNTXXiRJICgYDi4+NVUVERzekAAIBWqtlXUE4mGAxKkrxeb8R6r9frbAsGg+rRo0fkJBISlJaW5oz5rvr6etXX1zu3w+FwNKcNAAAs0ypexVNcXCyPx+MsmZmZsZ4SAABoQVENFJ/PJ0mqrq6OWF9dXe1s8/l8OnDgQMT2o0eP6uDBg86Y7yoqKlIoFHKWqqqqaE4bAABYJqqBkp2dLZ/Pp7KyMmddOBxWRUWF/H6/JMnv96umpkaVlZXOmHXr1qmxsVE5OTlN7tflcsntdkcsAACg7Wr2c1Bqa2v14YcfOrf37t2rt956S2lpacrKytK0adN03333qVevXsrOztbMmTOVkZGhMWPGSJL69u2r4cOHa/LkyVq8eLEaGho0depUjRs3jlfwAAAAST8gULZu3arLL7/cuV1YWChJmjBhgpYuXaq77rpLdXV1KigoUE1NjYYOHarS0lIlJSU591m2bJmmTp2qYcOGKT4+XmPHjtWCBQuicDgAAKAtiDPGmFhPornC4bA8Ho9CoRB/7sFPquf0F2M9hXbh49l5sZ4CgNNRVyd17vzN17W1UkrKSYc35/d3q3gVDwAAaF8IFAAAYB0CBQAAWIdAAQAA1iFQAACAdQgUAABgHQIFAABYh0ABAADWIVAAAIB1CBQAAGAdAgUAAFiHQAEAANYhUAAAgHUIFAAAYB0CBQAAWIdAAQAA1iFQAACAdQgUAABgHQIFAABYh0ABAADWIVAAAIB1CBQAAGAdAgUAAFiHQAEAANYhUAAAgHUIFAAAYB0CBQAAWIdAAQAA1iFQAACAdQgUAABgHQIFAABYh0ABAADWIVAAAIB1CBQAAGAdAgUAAFiHQAEAANYhUAAAgHUIFAAAYB0CBQAAWIdAAQAA1iFQAACAdaIeKMeOHdPMmTOVnZ2t5ORk/eIXv9Df/vY3GWOcMcYYzZo1S+np6UpOTlYgENCePXuiPRUAANBKRT1Q5syZo0WLFunhhx/Wrl27NGfOHM2dO1cLFy50xsydO1cLFizQ4sWLVVFRoZSUFOXm5urw4cPRng4AAGiFEqK9wzfffFOjR49WXl6eJKlnz556+umntXnzZknfXD2ZP3++ZsyYodGjR0uSnnrqKXm9Xq1evVrjxo2L9pQAtDI9p78Y6yk028ez82I9BaBNifoVlIsuukhlZWX64IMPJElvv/22Xn/9dY0YMUKStHfvXgWDQQUCAec+Ho9HOTk5Ki8vj/Z0AABAKxT1KyjTp09XOBxWnz591KFDBx07dkz333+/8vPzJUnBYFCS5PV6I+7n9Xqdbd9VX1+v+vp653Y4HI72tAEAgEWifgXlmWee0bJly7R8+XJt27ZNTz75pObNm6cnn3zyB++zuLhYHo/HWTIzM6M4YwAAYJuoB8qdd96p6dOna9y4cerfv7/Gjx+v22+/XcXFxZIkn88nSaquro64X3V1tbPtu4qKihQKhZylqqoq2tMGAAAWiXqgfPXVV4qPj9xthw4d1NjYKEnKzs6Wz+dTWVmZsz0cDquiokJ+v7/JfbpcLrnd7ogFAAC0XVF/DsqoUaN0//33KysrS/369dP27dv14IMP6sYbb5QkxcXFadq0abrvvvvUq1cvZWdna+bMmcrIyNCYMWOiPR0AANAKRT1QFi5cqJkzZ+qWW27RgQMHlJGRoZtuukmzZs1yxtx1112qq6tTQUGBampqNHToUJWWliopKSna0wEAAK1QnPn2W7y2EuFwWB6PR6FQiD/34CfVGt+fAz8N3gcF7VJdndS58zdf19ZKKSknHd6c3998Fg8AALAOgQIAAKxDoAAAAOsQKAAAwDoECgAAsA6BAgAArEOgAAAA6xAoAADAOgQKAACwDoECAACsQ6AAAADrECgAAMA6BAoAALAOgQIAAKxDoAAAAOsQKAAAwDoECgAAsA6BAgAArEOgAAAA6xAoAADAOgQKAACwDoECAACsQ6AAAADrECgAAMA6BAoAALAOgQIAAKxDoAAAAOsQKAAAwDoECgAAsA6BAgAArEOgAAAA6xAoAADAOgQKAACwDoECAACsQ6AAAADrJMR6Ami/ek5/MdZTAABYiisoAADAOgQKAACwDoECAACsQ6AAAADrECgAAMA6BAoAALBOiwTKp59+qj/+8Y/q1q2bkpOT1b9/f23dutXZbozRrFmzlJ6eruTkZAUCAe3Zs6clpgIAAFqhqAfKl19+qYsvvlgdO3bUyy+/rJ07d+of//iHunbt6oyZO3euFixYoMWLF6uiokIpKSnKzc3V4cOHoz0dAADQCkX9jdrmzJmjzMxMLVmyxFmXnZ3tfG2M0fz58zVjxgyNHj1akvTUU0/J6/Vq9erVGjduXLSnBAAAWpmoX0F5/vnnNWTIEP3+979Xjx49NGjQID3++OPO9r179yoYDCoQCDjrPB6PcnJyVF5e3uQ+6+vrFQ6HIxYAANB2RT1QPvroIy1atEi9evXSK6+8oj/96U+67bbb9OSTT0qSgsGgJMnr9Ubcz+v1Otu+q7i4WB6Px1kyMzOjPW0AAGCRqAdKY2OjzjvvPD3wwAMaNGiQCgoKNHnyZC1evPgH77OoqEihUMhZqqqqojhjAABgm6gHSnp6us4555yIdX379tW+ffskST6fT5JUXV0dMaa6utrZ9l0ul0tutztiAQAAbVfUA+Xiiy/W7t27I9Z98MEHOvPMMyV984RZn8+nsrIyZ3s4HFZFRYX8fn+0pwMAAFqhqL+K5/bbb9dFF12kBx54QNdcc402b96sxx57TI899pgkKS4uTtOmTdN9992nXr16KTs7WzNnzlRGRobGjBkT7ekAAIBWKOqBcv7552vVqlUqKirS//3f/yk7O1vz589Xfn6+M+auu+5SXV2dCgoKVFNTo6FDh6q0tFRJSUnRng4AAGiF4owxJtaTaK5wOCyPx6NQKMTzUVqxntNfjPUUgKj5eHZerKcA/PTq6qTOnb/5urZWSkk56fDm/P7ms3gAAIB1CBQAAGAdAgUAAFiHQAEAANYhUAAAgHUIFAAAYB0CBQAAWIdAAQAA1iFQAACAdQgUAABgHQIFAABYh0ABAADWIVAAAIB1CBQAAGAdAgUAAFiHQAEAANYhUAAAgHUIFAAAYB0CBQAAWIdAAQAA1iFQAACAdQgUAABgHQIFAABYh0ABAADWIVAAAIB1CBQAAGAdAgUAAFiHQAEAANYhUAAAgHUIFAAAYB0CBQAAWIdAAQAA1iFQAACAdQgUAABgHQIFAABYh0ABAADWIVAAAIB1CBQAAGAdAgUAAFiHQAEAANYhUAAAgHVaPFBmz56tuLg4TZs2zVl3+PBhTZkyRd26dVPnzp01duxYVVdXt/RUAABAK9GigbJlyxY9+uij+tWvfhWx/vbbb9cLL7yglStXasOGDdq/f7+uvvrqlpwKAABoRVosUGpra5Wfn6/HH39cXbt2ddaHQiE98cQTevDBB3XFFVdo8ODBWrJkid58801t2rSppaYDAABakRYLlClTpigvL0+BQCBifWVlpRoaGiLW9+nTR1lZWSovL29yX/X19QqHwxELAABouxJaYqcrVqzQtm3btGXLlhO2BYNBJSYmKjU1NWK91+tVMBhscn/FxcW69957W2KqAADAQlG/glJVVaU///nPWrZsmZKSkqKyz6KiIoVCIWepqqqKyn4BAICdoh4olZWVOnDggM477zwlJCQoISFBGzZs0IIFC5SQkCCv16sjR46opqYm4n7V1dXy+XxN7tPlcsntdkcsAACg7Yr6n3iGDRumd999N2LdxIkT1adPH919993KzMxUx44dVVZWprFjx0qSdu/erX379snv90d7OgAAoBWKeqB06dJF5557bsS6lJQUdevWzVk/adIkFRYWKi0tTW63W7feeqv8fr8uvPDCaE8HAAC0Qi3yJNlTeeihhxQfH6+xY8eqvr5eubm5euSRR2IxFQAAYKGfJFDWr18fcTspKUklJSUqKSn5Kb49AABoZfgsHgAAYB0CBQAAWIdAAQAA1iFQAACAdQgUAABgHQIFAABYh0ABAADWIVAAAIB1CBQAAGCdmLzVPaKv5/QXYz0FAACihisoAADAOlxBAYAoaI1XMT+enRfrKQDfiysoAADAOgQKAACwDoECAACsQ6AAAADrECgAAMA6BAoAALAOgQIAAKxDoAAAAOsQKAAAwDoECgAAsA6BAgAArEOgAAAA6xAoAADAOgQKAACwDoECAACsQ6AAAADrECgAAMA6BAoAALAOgQIAAKxDoAAAAOsQKAAAwDoECgAAsA6BAgAArEOgAAAA6xAoAADAOgQKAACwDoECAACsQ6AAAADrECgAAMA6UQ+U4uJinX/++erSpYt69OihMWPGaPfu3RFjDh8+rClTpqhbt27q3Lmzxo4dq+rq6mhPBQAAtFJRD5QNGzZoypQp2rRpk9auXauGhgZdeeWVqqurc8bcfvvteuGFF7Ry5Upt2LBB+/fv19VXXx3tqQAAgFYqIdo7LC0tjbi9dOlS9ejRQ5WVlbrkkksUCoX0xBNPaPny5briiiskSUuWLFHfvn21adMmXXjhhdGeEgAAaGVa/DkooVBIkpSWliZJqqysVENDgwKBgDOmT58+ysrKUnl5eZP7qK+vVzgcjlgAAEDb1aKB0tjYqGnTpuniiy/WueeeK0kKBoNKTExUampqxFiv16tgMNjkfoqLi+XxeJwlMzOzJacNAABirEUDZcqUKXrvvfe0YsWKH7WfoqIihUIhZ6mqqorSDAEAgI2i/hyU46ZOnao1a9Zo48aN+vnPf+6s9/l8OnLkiGpqaiKuolRXV8vn8zW5L5fLJZfL1VJTBQAAlon6FRRjjKZOnapVq1Zp3bp1ys7Ojtg+ePBgdezYUWVlZc663bt3a9++ffL7/dGeDgAAaIWifgVlypQpWr58uZ577jl16dLFeV6Jx+NRcnKyPB6PJk2apMLCQqWlpcntduvWW2+V3+/nFTwAAEBSCwTKokWLJEmXXXZZxPolS5bohhtukCQ99NBDio+P19ixY1VfX6/c3Fw98sgj0Z4KAABopaIeKMaYU45JSkpSSUmJSkpKov3tAQBAG8Bn8QAAAOsQKAAAwDoECgAAsA6BAgAArEOgAAAA6xAoAADAOi32VvetWc/pL8Z6CgAAtGtcQQEAANYhUAAAgHUIFAAAYB0CBQAAWIcnyQJAO9UaXxDw8ey8WE8BPxGuoAAAAOsQKAAAwDoECgAAsA6BAgAArEOgAAAA6xAoAADAOgQKAACwDoECAACsQ6AAAADrECgAAMA6BAoAALAOgQIAAKxDoAAAAOsQKAAAwDoECgAAsA6BAgAArEOgAAAA6xAoAADAOgQKAACwDoECAACsQ6AAAADrECgAAMA6BAoAALAOgQIAAKxDoAAAAOsQKAAAwDoECgAAsA6BAgAArEOgAAAA68Q0UEpKStSzZ08lJSUpJydHmzdvjuV0AACAJWIWKP/+979VWFioe+65R9u2bdOAAQOUm5urAwcOxGpKAADAEnHGGBOLb5yTk6Pzzz9fDz/8sCSpsbFRmZmZuvXWWzV9+vST3jccDsvj8SgUCsntdkd9bj2nvxj1fQIA0Jp8PDvv1IPq6qTOnb/5urZWSkk56fDm/P5OON2JRtORI0dUWVmpoqIiZ118fLwCgYDKy8tPGF9fX6/6+nrndigUkvTNgbaExvqvWmS/AAC0Fqf1O7au7tt3kI4dO619ns61kZgEyueff65jx47J6/VGrPd6vXr//fdPGF9cXKx77733hPWZmZktNkcAANozz/xm3iEj47SHHjp0SB6P56RjYhIozVVUVKTCwkLndmNjow4ePKhu3bopLi4uhjOD9E0RZ2ZmqqqqqkX+5IYfjnNjL86NvTg3LccYo0OHDinjNGImJoHSvXt3dejQQdXV1RHrq6ur5fP5Thjvcrnkcrki1qWmprbkFPEDuN1u/jNbinNjL86NvTg3LeNUV06Oi8mreBITEzV48GCVlZU56xobG1VWVia/3x+LKQEAAIvE7E88hYWFmjBhgoYMGaILLrhA8+fPV11dnSZOnBirKQEAAEvELFCuvfZa/e9//9OsWbMUDAY1cOBAlZaWnvDEWdjP5XLpnnvuOeHPcIg9zo29ODf24tzYIWbvgwIAAPB9+CweAABgHQIFAABYh0ABAADWIVAAAIB1CJR27uDBg8rPz5fb7VZqaqomTZqk2trak97n8OHDmjJlirp166bOnTtr7NixJ7zp3r59+5SXl6dOnTqpR48euvPOO3X06NGIMevXr9d5550nl8uls88+W0uXLo3YvnHjRo0aNUoZGRmKi4vT6tWro3HIVispKVHPnj2VlJSknJwcbd68+aTjV65cqT59+igpKUn9+/fXSy+9FLHdGKNZs2YpPT1dycnJCgQC2rNnT8SY0/kZeOedd/TrX/9aSUlJyszM1Ny5c6NzwK2Ijefm8OHDuuGGG9S/f38lJCRozJgxUTve1sTGc7N+/XqNHj1a6enpSklJ0cCBA7Vs2bLoHXR7YNCuDR8+3AwYMMBs2rTJvPbaa+bss88211133Unvc/PNN5vMzExTVlZmtm7dai688EJz0UUXOduPHj1qzj33XBMIBMz27dvNSy+9ZLp3726KioqcMR999JHp1KmTKSwsNDt37jQLFy40HTp0MKWlpc6Yl156yfzlL38xzz77rJFkVq1aFfXjt8mKFStMYmKi+de//mV27NhhJk+ebFJTU011dXWT49944w3ToUMHM3fuXLNz504zY8YM07FjR/Puu+86Y2bPnm08Ho9ZvXq1efvtt81VV11lsrOzzddff+2MOdXPQCgUMl6v1+Tn55v33nvPPP300yY5Odk8+uijLfdgWMbWc1NbW2tuvvlm89hjj5nc3FwzevToFnsMbGXrubn//vvNjBkzzBtvvGE+/PBDM3/+fBMfH29eeOGFlnsw2hgCpR3buXOnkWS2bNnirHv55ZdNXFyc+fTTT5u8T01NjenYsaNZuXKls27Xrl1GkikvLzfGfBMW8fHxJhgMOmMWLVpk3G63qa+vN8YYc9ddd5l+/fpF7Pvaa681ubm5TX7f9hAoF1xwgZkyZYpz+9ixYyYjI8MUFxc3Of6aa64xeXl5EetycnLMTTfdZIwxprGx0fh8PvP3v//d2V5TU2NcLpd5+umnjTGn9zPwyCOPmK5duzrnzhhj7r77btO7d+8fecSth63n5tsmTJjQLgOlNZyb40aOHGkmTpzY/INsp/gTTztWXl6u1NRUDRkyxFkXCAQUHx+vioqKJu9TWVmphoYGBQIBZ12fPn2UlZWl8vJyZ7/9+/ePeNO93NxchcNh7dixwxnz7X0cH3N8H+3NkSNHVFlZGfGYxMfHKxAIfO9jcqrHcO/evQoGgxFjPB6PcnJyIs7VqX4GysvLdckllygxMTHi++zevVtffvnljzxy+9l8btq71nZuQqGQ0tLSmn+g7RSB0o4Fg0H16NEjYl1CQoLS0tIUDAa/9z6JiYknfFij1+t17hMMBk94R+Djt081JhwO6+uvv/7Bx9Raff755zp27FiTj8nJzsXJxh//91RjTvUzcDrnsy2z+dy0d63p3DzzzDPasmULH+fSDARKGzR9+nTFxcWddHn//fdjPU0AaBdeffVVTZw4UY8//rj69esX6+m0GjH7LB60nDvuuEM33HDDScecddZZ8vl8OnDgQMT6o0eP6uDBg/L5fE3ez+fz6ciRI6qpqYm4ilJdXe3cx+fznfAs+uOv8vn2mO++8qe6ulput1vJycmnPMa2pnv37urQoUOTj8nJzsXJxh//t7q6Wunp6RFjBg4c6Iw51c/A932fb3+Ptszmc9PetYZzs2HDBo0aNUoPPfSQrr/++uYfZDvGFZQ26IwzzlCfPn1OuiQmJsrv96umpkaVlZXOfdetW6fGxkbl5OQ0ue/BgwerY8eOKisrc9bt3r1b+/btk9/vlyT5/X69++67Ef+B165dK7fbrXPOOccZ8+19HB9zfB/tTWJiogYPHhzxmDQ2NqqsrOx7H5NTPYbZ2dny+XwRY8LhsCoqKiLO1al+Bvx+vzZu3KiGhoaI79O7d2917dr1Rx65/Ww+N+2d7edm/fr1ysvL05w5c1RQUPDjD7i9ifWzdBFbw4cPN4MGDTIVFRXm9ddfN7169Yp4qdx///tf07t3b1NRUeGsu/nmm01WVpZZt26d2bp1q/H7/cbv9zvbj7/M+MorrzRvvfWWKS0tNWeccUaTLzO+8847za5du0xJSckJLzM+dOiQ2b59u9m+fbuRZB588EGzfft288knn7TwoxIbK1asMC6XyyxdutTs3LnTFBQUmNTUVOfVUOPHjzfTp093xr/xxhsmISHBzJs3z+zatcvcc889Tb5cMjU11Tz33HPmnXfeMaNHj27y5ZIn+xmoqakxXq/XjB8/3rz33ntmxYoVplOnTu3uZcY2nhtjjNmxY4fZvn27GTVqlLnsssuc/zPtha3nZt26daZTp06mqKjIfPbZZ87yxRdf/ASPSttAoLRzX3zxhbnuuutM586djdvtNhMnTjSHDh1ytu/du9dIMq+++qqz7uuvvza33HKL6dq1q+nUqZP57W9/az777LOI/X788cdmxIgRJjk52XTv3t3ccccdpqGhIWLMq6++agYOHGgSExPNWWedZZYsWXLCdkknLBMmTIj2w2CNhQsXmqysLJOYmGguuOACs2nTJmfbpZdeesKxP/PMM+aXv/ylSUxMNP369TMvvvhixPbGxkYzc+ZM4/V6jcvlMsOGDTO7d++OGHOqnwFjjHn77bfN0KFDjcvlMj/72c/M7Nmzo3vgrYCt5+bMM89s8v9Je2LjuZkwYUKT5+XSSy+N+vG3VXHGGPOTX7YBAAA4CZ6DAgAArEOgAAAA6xAoAADAOgQKAACwDoECAACsQ6AAAADrECgAAMA6BAoAALAOgQIAAKxDoAAAAOsQKAAAwDoECgAAsM7/A3cHPtDtgOU8AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(distr)\n",
    "plt.axvline(est, c='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
