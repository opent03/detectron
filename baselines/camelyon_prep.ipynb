{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os \n",
    "import sys\n",
    "import pickle\n",
    "from sklearn.decomposition import PCA\n",
    "from functools import partial\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.models import resnet18\n",
    "from torchvision.transforms import Compose, ToTensor, Resize\n",
    "from typing import Union\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wilds.datasets.camelyon17_dataset import Camelyon17Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Sep 28 16:14:51 2024       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A40          On   | 00000000:06:00.0 Off |                    0 |\n",
      "|  0%   39C    P0    58W / 300W |      0MiB / 46068MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Camelyon17 Training\n",
    "\n",
    "We proceed in steps: \n",
    "- Split the Camelyon17 dataset into different splits corresponding to different iid/ood settings.\n",
    "- Train and validate on the train/id_val split, while reporting OOD-performance on the test set to assess some model degradation.\n",
    "- Extract features with the newly trained resnet and ship it out.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.enabled = True\n",
    "\n",
    "learning_rate=1e-4\n",
    "batch_size=64\n",
    "epochs=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "from torchvision.models import resnet18, ResNet18_Weights, ResNet\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Camelyon17Dataset(root_dir='/scratch/ssd004/scratch/opent03/', download=False)\n",
    "splits = ['train', 'id_val', 'val', 'test']\n",
    "datasets = {}\n",
    "dataloaders = {}\n",
    "for split in splits:\n",
    "    datasets[split] = dataset.get_subset(split=split, transform=ToTensor())\n",
    "    #dataloaders[split] = torch.utils.data.DataLoader(datasets[split], batch_size=batch_size, num_workers=20, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Take Camelyon17 data splits and add to custom datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_memory(dataset):\n",
    "    i = 0\n",
    "    img_size = (3, 96, 96)\n",
    "    num_images = len(dataset)\n",
    "    stacked_images = torch.empty((num_images, *img_size))\n",
    "    labels = torch.empty((num_images))\n",
    "    for torch_img, label, _ in tqdm(dataset):\n",
    "        stacked_images[i] = torch_img\n",
    "        labels[i] = label\n",
    "        i += 1\n",
    "    return stacked_images, labels\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 302436/302436 [07:18<00:00, 690.16it/s]\n",
      "100%|██████████| 33560/33560 [00:48<00:00, 690.89it/s]\n",
      "100%|██████████| 34904/34904 [00:50<00:00, 685.68it/s]\n",
      "100%|██████████| 85054/85054 [02:44<00:00, 518.27it/s]\n"
     ]
    }
   ],
   "source": [
    "datasets_memory = {}\n",
    "for split in splits:\n",
    "    datasets_memory[split] = load_memory(datasets[split])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CudaDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, images, labels):\n",
    "        self.images = images.cuda()\n",
    "        self.labels = labels.cuda()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.images[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda_datasets = {}\n",
    "for split in tqdm(splits):\n",
    "    images, labels = datasets_memory[split]\n",
    "    cuda_datasets[split] = CudaDataset(images, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(cuda_datasets['train'], batch_size=batch_size, shuffle=True)\n",
    "valloader = DataLoader(cuda_datasets['id_val'], batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "model.fc = nn.Linear(512, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loader, criterion, optimizer):\n",
    "    # Train\n",
    "    model.train()\n",
    "    for imgs, labels in tqdm(loader):\n",
    "        #imgs, labels = imgs.cuda(non_blocking=True), labels.cuda(non_blocking=True).float()\n",
    "        output = model(imgs).squeeze(-1)\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "def evaluate(model, loader, on_cuda=True):\n",
    "    # IID eval\n",
    "    model.eval()\n",
    "    count = 0\n",
    "    acc = 0\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels, in tqdm(loader):\n",
    "            if not on_cuda:\n",
    "                imgs, labels = imgs.cuda(), labels.cuda()\n",
    "            output = F.sigmoid(model(imgs).squeeze(-1))\n",
    "            preds = torch.round(output)\n",
    "            acc += torch.sum(preds == labels)\n",
    "            count += len(labels)\n",
    "    acc = (acc/count).item()\n",
    "    return acc    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running epoch 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4726/4726 [00:56<00:00, 83.35it/s]\n",
      "100%|██████████| 525/525 [00:01<00:00, 266.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(33223, device='cuda:0')\n",
      "33560\n",
      "iid: 0.9899582862854004,\tood: 0.9899582862854004\n",
      "Running epoch 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4726/4726 [00:56<00:00, 83.37it/s]\n",
      "100%|██████████| 525/525 [00:01<00:00, 285.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(33322, device='cuda:0')\n",
      "33560\n",
      "iid: 0.992908239364624,\tood: 0.992908239364624\n",
      "Running epoch 3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 958/4726 [00:11<00:45, 83.25it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[83], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRunning epoch \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m----> 7\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     iid_acc \u001b[38;5;241m=\u001b[39m evaluate(model, valloader)\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m#ood_acc = evaluate(model, dataloaders['val'])\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[82], line 6\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, loader, criterion, optimizer)\u001b[0m\n\u001b[1;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m imgs, labels \u001b[38;5;129;01min\u001b[39;00m tqdm(loader):\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m#imgs, labels = imgs.cuda(non_blocking=True), labels.cuda(non_blocking=True).float()\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimgs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      7\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m      8\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(output, labels)\n",
      "File \u001b[0;32m~/.conda/envs/dis/lib/python3.9/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/dis/lib/python3.9/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/dis/lib/python3.9/site-packages/torchvision/models/resnet.py:285\u001b[0m, in \u001b[0;36mResNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/dis/lib/python3.9/site-packages/torchvision/models/resnet.py:275\u001b[0m, in \u001b[0;36mResNet._forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    273\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer1(x)\n\u001b[1;32m    274\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer2(x)\n\u001b[0;32m--> 275\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    276\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer4(x)\n\u001b[1;32m    278\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mavgpool(x)\n",
      "File \u001b[0;32m~/.conda/envs/dis/lib/python3.9/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/dis/lib/python3.9/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/dis/lib/python3.9/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/.conda/envs/dis/lib/python3.9/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/dis/lib/python3.9/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/dis/lib/python3.9/site-packages/torchvision/models/resnet.py:97\u001b[0m, in \u001b[0;36mBasicBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     94\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(out)\n\u001b[1;32m     96\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(out)\n\u001b[0;32m---> 97\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbn2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownsample \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    100\u001b[0m     identity \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownsample(x)\n",
      "File \u001b[0;32m~/.conda/envs/dis/lib/python3.9/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/dis/lib/python3.9/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/dis/lib/python3.9/site-packages/torch/nn/modules/batchnorm.py:175\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    168\u001b[0m     bn_training \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_mean \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_var \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    170\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;124;03mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;124;03mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;124;03mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 175\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[1;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_mean\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_var\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbn_training\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexponential_average_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/dis/lib/python3.9/site-packages/torch/nn/functional.py:2509\u001b[0m, in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m training:\n\u001b[1;32m   2507\u001b[0m     _verify_batch_size(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize())\n\u001b[0;32m-> 2509\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2510\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_mean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_var\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcudnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menabled\u001b[49m\n\u001b[1;32m   2511\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "patience = 0\n",
    "best = 0\n",
    "best_state_dict = None\n",
    "model = model.cuda()\n",
    "for epoch in range(epochs):\n",
    "    print('Running epoch {}...'.format(epoch + 1))\n",
    "    train(model, trainloader, criterion, optimizer)\n",
    "    iid_acc = evaluate(model, valloader)\n",
    "    #ood_acc = evaluate(model, dataloaders['val'])\n",
    "    if iid_acc > best:\n",
    "        best = iid_acc\n",
    "        best_state_dict = model.state_dict().copy()\n",
    "        patience = 0\n",
    "    else:\n",
    "        patience += 1\n",
    "    print('iid: {},\\tood: {}'.format(iid_acc, iid_acc))\n",
    "    if patience > 5:\n",
    "        print('Max patience reached! Returning...')\n",
    "        break    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ood_loader = DataLoader(datasets['val'], batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 546/546 [00:52<00:00, 10.33it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8876059651374817"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(model, val_ood_loader, on_cuda=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(best_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "del cuda_datasets['train'].labels\n",
    "del cuda_datasets['id_val'].labels\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Sep 28 16:12:23 2024       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A40          On   | 00000000:06:00.0 Off |                    0 |\n",
      "|  0%   38C    P0    86W / 300W |  41934MiB / 46068MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1501      C   ...conda/envs/dis/bin/python    41932MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('resnet18_camelyon17.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rep(model, dataset):\n",
    "    # Takes in raw camelyon17 data\n",
    "    model = model.cuda()\n",
    "    model.eval()\n",
    "    new_data = []\n",
    "    labels_list = []\n",
    "    loader = DataLoader(dataset, batch_size=2048, shuffle=True)\n",
    "    for images, labels, _ in tqdm(loader):\n",
    "        images = images.cuda()\n",
    "        labels_list.append(labels)\n",
    "        rep = model(images) # should be [1024, 512, 1, 1]\n",
    "        rep = rep.squeeze(-1).squeeze(-1)# should be [1024, 512]\n",
    "        new_data.append(rep.cpu().detach().numpy())\n",
    "    np_data = np.concatenate(new_data, axis=0)\n",
    "    np_labels = np.concatenate(labels_list)\n",
    "    return np_data, np_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "rep_model = torch.nn.Sequential(*list(model.children())[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 148/148 [07:22<00:00,  2.99s/it]\n",
      "100%|██████████| 17/17 [00:48<00:00,  2.88s/it]\n",
      "100%|██████████| 18/18 [00:51<00:00,  2.84s/it]\n",
      "100%|██████████| 42/42 [02:09<00:00,  3.09s/it]\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train = get_rep(rep_model, datasets['train'])\n",
    "x_idval, y_idval = get_rep(rep_model, datasets['id_val'])\n",
    "x_val, y_val = get_rep(rep_model, datasets['val'])\n",
    "x_test, y_test = get_rep(rep_model, datasets['test'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(302436, 512)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(best_state_dict, 'baselines/resnet18_camelyon17.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data = {\n",
    "    'x_train': x_train,\n",
    "    'x_idval': x_idval,\n",
    "    'x_val': x_val,\n",
    "    'x_test': x_test\n",
    "}\n",
    "processed_labels = {\n",
    "    'y_train': y_train,\n",
    "    'y_idval': y_idval,\n",
    "    'y_val': y_val,\n",
    "    'y_test': y_test\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('baselines/data/camelyon17_features.pkl', 'wb') as f:\n",
    "    pickle.dump(processed_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('baselines/data/camelyon17_labels.pkl', 'wb') as f:\n",
    "    pickle.dump(processed_labels, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def load_and_process_camelyon17(n_components=20):\n",
    "    with open('baselines/data/camelyon17_features.pkl', 'rb') as f:\n",
    "        datadict = pickle.load(f)\n",
    "    with open('baselines/data/camelyon17_labels.pkl', 'rb') as f:\n",
    "        labelsdict = pickle.load(f)\n",
    "    \n",
    "    pca = PCA(n_components=n_components)\n",
    "    pca.fit(datadict['x_train'])\n",
    "    x_train, x_test = pca.transform(datadict['x_train']), pca.transform(datadict['x_test'])\n",
    "    y_train, y_test = labelsdict['y_train'], labelsdict['y_test']\n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = load_and_process_camelyon17()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from baselines.divergence import Divergence, permutation_test\n",
    "distance = Divergence(name='h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:02<00:00, 246.80it/s]\n"
     ]
    }
   ],
   "source": [
    "flag, distr, est = permutation_test(distance, X=x_train, Y=x_test, perms=500, enable_tqdm=True, max_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.lines.Line2D at 0x7fcae3597e50>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(distr)\n",
    "plt.axvline(est, c='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
